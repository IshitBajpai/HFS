{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('display.max_rows', None)\n",
    "from yahooquery import Ticker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [],
   "source": [
    "year = 2024\n",
    "df = pd.read_csv(f'Data/sp500_wrds_{year}_fundamental.csv')\n",
    "price_df = pd.read_csv(f'Data/sp500_wrds_{year}_price.csv') # include 12 months before data\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "76"
      ]
     },
     "execution_count": 347,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial_columns = ['permno', 'adate', 'qdate', 'public_date', 'bm', 'evm', 'pe_op_basic',\n",
    "#        'pe_op_dil', 'pe_exi', 'ps', 'pcf', 'dpr', 'npm', 'opmad', 'gpm',\n",
    "#        'ptpm', 'cfm', 'roa', 'roe', 'roce', 'efftax', 'aftret_eq',\n",
    "#        'aftret_invcapx', 'aftret_equity', 'pretret_noa', 'GProf',\n",
    "#        'equity_invcap', 'debt_invcap', 'totdebt_invcap', 'capital_ratio',\n",
    "#        'int_debt', 'int_totdebt', 'cash_lt', 'invt_act', 'rect_act', 'debt_at',\n",
    "#        'debt_ebitda', 'short_debt', 'curr_debt', 'lt_debt', 'profit_lct',\n",
    "#        'ocf_lct', 'cash_debt', 'fcf_ocf', 'lt_ppent', 'dltt_be', 'debt_assets',\n",
    "#        'debt_capital', 'de_ratio', 'intcov', 'intcov_ratio', 'inv_turn',\n",
    "#        'at_turn', 'rect_turn', 'pay_turn', 'sale_equity', 'sale_nwc',\n",
    "#        'rd_sale', 'adv_sale', 'staff_sale', 'accrual', 'ptb', 'PEG_trailing',\n",
    "#        'divyield', 'TICKER']\n",
    "# # some are dropped due to high missing values or redundancy after this block\n",
    "\n",
    "# df = df[initial_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_drop = ['permno','adate', 'qdate','PEG_trailing','inv_turn', 'sale_nwc','profit_lct','ocf_lct','curr_debt', 'pretret_noa', 'intcov', 'intcov_ratio', 'rect_act','invt_act']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=cols_to_drop)\n",
    "df = df.rename(columns={'TICKER': 'ticker', 'public_date': 'date'})\n",
    "df = df.dropna(subset=['ticker'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.isna().sum()\n",
    "df['date'] = pd.to_datetime(df['date'], format='%Y-%m-%d')\n",
    "# df.set_index('date', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remoce % sign from divyield and convert to float\n",
    "df[\"divyield\"] = df[\"divyield\"].str.rstrip('%')\n",
    "df[\"divyield\"] = df[\"divyield\"].fillna(0)\n",
    "df[\"divyield\"] = df[\"divyield\"].astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sort_values(['ticker', 'date'])\n",
    "df = df.groupby('ticker').apply(lambda x: x.ffill().bfill())\n",
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gvkey</th>\n",
       "      <th>date</th>\n",
       "      <th>CAPEI</th>\n",
       "      <th>bm</th>\n",
       "      <th>evm</th>\n",
       "      <th>pe_op_basic</th>\n",
       "      <th>pe_op_dil</th>\n",
       "      <th>pe_exi</th>\n",
       "      <th>pe_inc</th>\n",
       "      <th>ps</th>\n",
       "      <th>...</th>\n",
       "      <th>sale_invcap</th>\n",
       "      <th>sale_equity</th>\n",
       "      <th>rd_sale</th>\n",
       "      <th>adv_sale</th>\n",
       "      <th>staff_sale</th>\n",
       "      <th>accrual</th>\n",
       "      <th>ptb</th>\n",
       "      <th>divyield</th>\n",
       "      <th>ticker</th>\n",
       "      <th>cusip</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>126554</td>\n",
       "      <td>2024-01-31</td>\n",
       "      <td>34.692</td>\n",
       "      <td>0.195</td>\n",
       "      <td>19.343</td>\n",
       "      <td>29.908</td>\n",
       "      <td>30.116</td>\n",
       "      <td>31.050</td>\n",
       "      <td>31.050</td>\n",
       "      <td>5.579</td>\n",
       "      <td>...</td>\n",
       "      <td>0.786</td>\n",
       "      <td>1.169</td>\n",
       "      <td>0.070</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.050</td>\n",
       "      <td>6.480</td>\n",
       "      <td>0.726</td>\n",
       "      <td>A</td>\n",
       "      <td>00846U10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>126554</td>\n",
       "      <td>2024-02-29</td>\n",
       "      <td>36.633</td>\n",
       "      <td>0.195</td>\n",
       "      <td>19.343</td>\n",
       "      <td>31.577</td>\n",
       "      <td>31.796</td>\n",
       "      <td>32.783</td>\n",
       "      <td>32.783</td>\n",
       "      <td>5.891</td>\n",
       "      <td>...</td>\n",
       "      <td>0.786</td>\n",
       "      <td>1.169</td>\n",
       "      <td>0.070</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.050</td>\n",
       "      <td>6.842</td>\n",
       "      <td>0.687</td>\n",
       "      <td>A</td>\n",
       "      <td>00846U10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>126554</td>\n",
       "      <td>2024-03-31</td>\n",
       "      <td>39.881</td>\n",
       "      <td>0.162</td>\n",
       "      <td>23.184</td>\n",
       "      <td>33.297</td>\n",
       "      <td>33.605</td>\n",
       "      <td>34.645</td>\n",
       "      <td>34.645</td>\n",
       "      <td>6.331</td>\n",
       "      <td>...</td>\n",
       "      <td>0.787</td>\n",
       "      <td>1.153</td>\n",
       "      <td>0.072</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.067</td>\n",
       "      <td>6.891</td>\n",
       "      <td>0.649</td>\n",
       "      <td>A</td>\n",
       "      <td>00846U10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>126554</td>\n",
       "      <td>2024-04-30</td>\n",
       "      <td>37.559</td>\n",
       "      <td>0.162</td>\n",
       "      <td>23.184</td>\n",
       "      <td>31.359</td>\n",
       "      <td>31.649</td>\n",
       "      <td>32.629</td>\n",
       "      <td>32.629</td>\n",
       "      <td>5.963</td>\n",
       "      <td>...</td>\n",
       "      <td>0.787</td>\n",
       "      <td>1.153</td>\n",
       "      <td>0.072</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.067</td>\n",
       "      <td>6.490</td>\n",
       "      <td>0.689</td>\n",
       "      <td>A</td>\n",
       "      <td>00846U10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>126554</td>\n",
       "      <td>2024-05-31</td>\n",
       "      <td>35.742</td>\n",
       "      <td>0.162</td>\n",
       "      <td>23.184</td>\n",
       "      <td>29.842</td>\n",
       "      <td>30.118</td>\n",
       "      <td>31.050</td>\n",
       "      <td>31.050</td>\n",
       "      <td>5.674</td>\n",
       "      <td>...</td>\n",
       "      <td>0.787</td>\n",
       "      <td>1.153</td>\n",
       "      <td>0.072</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.067</td>\n",
       "      <td>6.176</td>\n",
       "      <td>0.724</td>\n",
       "      <td>A</td>\n",
       "      <td>00846U10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 62 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    gvkey       date   CAPEI     bm     evm  pe_op_basic  pe_op_dil  pe_exi  \\\n",
       "0  126554 2024-01-31  34.692  0.195  19.343       29.908     30.116  31.050   \n",
       "1  126554 2024-02-29  36.633  0.195  19.343       31.577     31.796  32.783   \n",
       "2  126554 2024-03-31  39.881  0.162  23.184       33.297     33.605  34.645   \n",
       "3  126554 2024-04-30  37.559  0.162  23.184       31.359     31.649  32.629   \n",
       "4  126554 2024-05-31  35.742  0.162  23.184       29.842     30.118  31.050   \n",
       "\n",
       "   pe_inc     ps  ...  sale_invcap  sale_equity  rd_sale  adv_sale  \\\n",
       "0  31.050  5.579  ...        0.786        1.169    0.070     0.008   \n",
       "1  32.783  5.891  ...        0.786        1.169    0.070     0.008   \n",
       "2  34.645  6.331  ...        0.787        1.153    0.072     0.008   \n",
       "3  32.629  5.963  ...        0.787        1.153    0.072     0.008   \n",
       "4  31.050  5.674  ...        0.787        1.153    0.072     0.008   \n",
       "\n",
       "   staff_sale  accrual    ptb  divyield  ticker     cusip  \n",
       "0         0.0   -0.050  6.480     0.726       A  00846U10  \n",
       "1         0.0   -0.050  6.842     0.687       A  00846U10  \n",
       "2         0.0   -0.067  6.891     0.649       A  00846U10  \n",
       "3         0.0   -0.067  6.490     0.689       A  00846U10  \n",
       "4         0.0   -0.067  6.176     0.724       A  00846U10  \n",
       "\n",
       "[5 rows x 62 columns]"
      ]
     },
     "execution_count": 354,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5438, 62)"
      ]
     },
     "execution_count": 355,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2022 specific"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [],
   "source": [
    "# renam fb ticker to meta (2022 change)\n",
    "df['ticker'] = df['ticker'].replace({'FB': 'META'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "468\n"
     ]
    }
   ],
   "source": [
    "print(len(df[\"ticker\"].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['tic', 'datadate', 'gvkey', 'ggroup', 'gind', 'gsector', 'cshtrm',\n",
       "       'prccm'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 358,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "price_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dictionary to map ticker to gind\n",
    "gind_mapping = price_df.set_index('tic')['gind'].to_dict()\n",
    "gsec_mapping = price_df.set_index('tic')['gsector'].to_dict()\n",
    "df['gind'] = df['ticker'].map(gind_mapping)\n",
    "df['gsector'] = df['ticker'].map(gsec_mapping)\n",
    "\n",
    "\n",
    "price_df = price_df[['tic', 'datadate', 'cshtrm', 'prccm']]\n",
    "price_df = price_df.rename(columns={'tic': 'ticker', 'datadate': 'date', 'cshtrm': 'volume', 'prccm': 'price'}) # rename columns\n",
    "price_df['date'] = pd.to_datetime(price_df['date'], format='%Y-%m-%d')\n",
    "# price_df.set_index('date', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [],
   "source": [
    "# group = price_df.groupby('ticker')\n",
    "# price_df['ret_1m']  = group['price'].transform(lambda x: x.pct_change())\n",
    "# price_df['ret_3m']  = group['price'].transform(lambda x: x.pct_change(3))\n",
    "# price_df['ret_6m']  = group['price'].transform(lambda x: x.pct_change(6))\n",
    "\n",
    "# # 1. Simple Moving Averages\n",
    "# price_df['SMA_3']  = group['ret_1m'].transform(lambda x: x.rolling(3).mean())\n",
    "# price_df['SMA_6']  = group['ret_1m'].transform(lambda x: x.rolling(6).mean())\n",
    "\n",
    "# # 3. Volatility (Rolling Std of returns)\n",
    "# price_df['vol_3m']  = group['ret_1m'].transform(lambda x: x.rolling(3).std())\n",
    "# price_df['vol_6m']  = group['ret_1m'].transform(lambda x: x.rolling(6).std())\n",
    "# # price_df['vol_12m'] = group['ret_1m'].transform(lambda x: x.rolling(12).std())\n",
    "\n",
    "# # 4. Exponential Moving Average\n",
    "# price_df['EMA_6']  = group['ret_1m'].transform(lambda x: x.ewm(span=3, adjust=False).mean())\n",
    "# price_df['EMA_12'] = group['ret_1m'].transform(lambda x: x.ewm(span=6, adjust=False).mean())\n",
    "\n",
    "\n",
    "# # 7. Volume moving average\n",
    "# price_df['vol_SMA_3'] = group['volume'].transform(lambda x: x.rolling(3).mean())\n",
    "# price_df['vol_SMA_6'] = group['volume'].transform(lambda x: x.rolling(6).mean())\n",
    "\n",
    "# # 8. Volume Rate of Change\n",
    "# price_df['vol_ROC'] = group['volume'].transform(lambda x: x.pct_change())\n",
    "\n",
    "# # 9. OBV (On-Balance Volume)\n",
    "# def obv(df):\n",
    "#     sign = df['price'].diff().apply(lambda x: 1 if x>0 else -1 if x<0 else 0)\n",
    "#     return (sign * df['volume']).cumsum()\n",
    "\n",
    "# price_df['OBV'] = group.apply(obv).reset_index(level=0, drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming price_df is set up\n",
    "group = price_df.groupby('ticker')\n",
    "\n",
    "# --- 1. Base Returns (Correct) ---\n",
    "price_df['ret_1m']  = group['price'].transform(lambda x: x.pct_change())\n",
    "price_df['ret_3m']  = group['price'].transform(lambda x: x.pct_change(3))\n",
    "price_df['ret_6m']  = group['price'].transform(lambda x: x.pct_change(6))\n",
    "\n",
    "# --- 2. SMA of Returns (Correct) ---\n",
    "price_df['SMA_3']   = group['ret_1m'].transform(lambda x: x.rolling(3).mean())\n",
    "price_df['SMA_6']   = group['ret_1m'].transform(lambda x: x.rolling(6).mean())\n",
    "\n",
    "# --- 3. Volatility (Correct) ---\n",
    "price_df['vol_3m']  = group['ret_1m'].transform(lambda x: x.rolling(3).std())\n",
    "price_df['vol_6m']  = group['ret_1m'].transform(lambda x: x.rolling(6).std())\n",
    "\n",
    "# --- 4. EMA of Returns (Fixed parameters) ---\n",
    "# Fixed: span should match the variable name concept (or close to it)\n",
    "price_df['EMA_3']   = group['ret_1m'].transform(lambda x: x.ewm(span=3, adjust=False).mean())\n",
    "price_df['EMA_6']  = group['ret_1m'].transform(lambda x: x.ewm(span=6, adjust=False).mean())\n",
    "\n",
    "# --- 5. Relative Volume (Fixed Volume SMA) ---\n",
    "# logic: Current Volume / Average Volume\n",
    "# If result > 1, volume is higher than average.\n",
    "price_df['RVOL_3'] = group['volume'].transform(lambda x: x / x.rolling(3).mean())\n",
    "price_df['RVOL_6'] = group['volume'].transform(lambda x: x / x.rolling(6).mean())\n",
    "\n",
    "# --- 6. Volume Rate of Change (Correct) ---\n",
    "price_df['vol_ROC'] = group['volume'].transform(lambda x: x.pct_change())\n",
    "\n",
    "# --- 7. Volume-Weighted Momentum (Fixed OBV) ---\n",
    "# Instead of cumulative OBV, we look at the immediate impact of volume on price.\n",
    "# Logic: Return * Relative Volume. \n",
    "# A high return on high volume = Strong Signal.\n",
    "price_df['vol_mom'] = price_df['ret_1m'] * price_df['RVOL_3']\n",
    "\n",
    "# Final Cleanup\n",
    "price_df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ticker     0\n",
       "date       0\n",
       "volume     0\n",
       "price      0\n",
       "ret_1m     0\n",
       "ret_3m     0\n",
       "ret_6m     0\n",
       "SMA_3      0\n",
       "SMA_6      0\n",
       "vol_3m     0\n",
       "vol_6m     0\n",
       "EMA_3      0\n",
       "EMA_6      0\n",
       "RVOL_3     0\n",
       "RVOL_6     0\n",
       "vol_ROC    0\n",
       "vol_mom    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 362,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "price_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "\n",
    "\n",
    "# # -------------------------------------------------------------------------\n",
    "# # 2. CALCULATIONS\n",
    "# # -------------------------------------------------------------------------\n",
    "# group = price_df.groupby('ticker')\n",
    "\n",
    "# # --- A. Base Returns (Momentum) ---\n",
    "# # Pure percentage change over time windows\n",
    "# price_df['ret_1m']  = group['price'].transform(lambda x: x.pct_change())\n",
    "# price_df['ret_3m']  = group['price'].transform(lambda x: x.pct_change(3))\n",
    "# price_df['ret_6m']  = group['price'].transform(lambda x: x.pct_change(6))\n",
    "# # price_df['ret_12m'] = group['price'].transform(lambda x: x.pct_change(12))\n",
    "\n",
    "# # --- B. Return Moving Averages (Trend of Momentum) ---\n",
    "# # Averaging the *returns*, not the price, to keep it scale-independent\n",
    "# price_df['SMA_3_ret']  = group['ret_1m'].transform(lambda x: x.rolling(3).mean())\n",
    "# price_df['SMA_6_ret']  = group['ret_1m'].transform(lambda x: x.rolling(6).mean())\n",
    "\n",
    "# # --- C. Volatility (Risk) ---\n",
    "# # Rolling standard deviation of returns\n",
    "# price_df['vol_3m']  = group['ret_1m'].transform(lambda x: x.rolling(3).std())\n",
    "# price_df['vol_6m']  = group['ret_1m'].transform(lambda x: x.rolling(6).std())\n",
    "# price_df['vol_12m'] = group['ret_1m'].transform(lambda x: x.rolling(12).std())\n",
    "\n",
    "# # --- D. Volatility Ratio (Regime Change) ---\n",
    "# # Compares short-term vol to long-term vol (>1 = expanding volatility)\n",
    "# price_df['vol_ratio'] = price_df['vol_3m'] / price_df['vol_12m']\n",
    "\n",
    "# # --- E. Distance from Moving Average (Trend Oscillator) ---\n",
    "# # Percentage distance from the 12-month average price\n",
    "# price_df['dist_SMA_12'] = group['price'].transform(\n",
    "#     lambda x: (x - x.rolling(12).mean()) / x.rolling(12).mean()\n",
    "# )\n",
    "\n",
    "# # --- F. Distance from High (Drawdown) ---\n",
    "# # How far is current price from the 12-month maximum? (0 = at high, -0.2 = 20% down)\n",
    "# price_df['dist_high_12'] = group['price'].transform(\n",
    "#     lambda x: (x / x.rolling(12).max()) - 1\n",
    "# )\n",
    "\n",
    "# # --- G. Bollinger %B / Z-Score (Statistical Position) ---\n",
    "# # Number of standard deviations the price is from the 12-month mean\n",
    "# def z_score_price(x, window=12):\n",
    "#     r_mean = x.rolling(window).mean()\n",
    "#     r_std = x.rolling(window).std()\n",
    "#     return (x - r_mean) / r_std\n",
    "\n",
    "# price_df['price_zscore_12'] = group['price'].transform(z_score_price)\n",
    "\n",
    "# # --- H. RSI (Relative Strength Index) ---\n",
    "# # Standard RSI is naturally 0-100 and scale independent\n",
    "# def calculate_rsi(series, period=14):\n",
    "#     delta = series.diff()\n",
    "#     gain = delta.clip(lower=0).rolling(period).mean()\n",
    "#     loss = -delta.clip(upper=0).rolling(period).mean()\n",
    "#     rs = gain / loss.replace(0, np.nan) \n",
    "#     return 100 - (100 / (1 + rs))\n",
    "\n",
    "# price_df['RSI_14'] = group['price'].transform(calculate_rsi)\n",
    "\n",
    "# # --- I. Normalized MACD (Percentage Price Oscillator) ---\n",
    "# # (Fast EMA - Slow EMA) divided by Price to get a percentage\n",
    "# def normalized_macd(x):\n",
    "#     exp1 = x.ewm(span=12, adjust=False).mean()\n",
    "#     exp2 = x.ewm(span=26, adjust=False).mean()\n",
    "#     return (exp1 - exp2) / x \n",
    "\n",
    "# price_df['MACD_norm'] = group['price'].transform(normalized_macd)\n",
    "\n",
    "# # --- J. Volume Indicators (Normalized) ---\n",
    "\n",
    "# # 1. Volume Rate of Change\n",
    "# price_df['vol_ROC'] = group['volume'].transform(lambda x: x.pct_change())\n",
    "\n",
    "# # 2. Relative Volume (RVOL) - Ratio of current vol to 10-month avg\n",
    "# def relative_volume(x, period=10):\n",
    "#     return x / x.rolling(period).mean()\n",
    "\n",
    "# price_df['RVOL_10'] = group['volume'].transform(relative_volume)\n",
    "\n",
    "# # 3. Volume Weighted Momentum\n",
    "# # Combines price strength with volume conviction\n",
    "# price_df['vol_wgt_mom'] = price_df['ret_1m'] * price_df['RVOL_10']\n",
    "\n",
    "# # -------------------------------------------------------------------------\n",
    "# # 3. CLEANUP\n",
    "# # -------------------------------------------------------------------------\n",
    "\n",
    "# # Because we used rolling windows (up to 12 months), the first 12 rows \n",
    "# # per ticker will have NaNs. \n",
    "# # price_df_clean = price_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ticker', 'date', 'volume', 'price', 'ret_1m', 'ret_3m', 'ret_6m',\n",
       "       'SMA_3', 'SMA_6', 'vol_3m', 'vol_6m', 'EMA_3', 'EMA_6', 'RVOL_3',\n",
       "       'RVOL_6', 'vol_ROC', 'vol_mom'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 364,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "price_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9233, 17)"
      ]
     },
     "execution_count": 365,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "price_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [],
   "source": [
    "nans_col = df.isna().sum()\n",
    "missing_columns = nans_col[nans_col > 0]\n",
    "\n",
    "for col in missing_columns.index:\n",
    "    if col not in ['gind', 'gsector']:\n",
    "        # 1. Fill using industry mean\n",
    "        df[col] = df[col].fillna(df.groupby('gind')[col].transform('mean'))\n",
    "        # 2. Fill remaining using sector mean\n",
    "        df[col] = df[col].fillna(df.groupby('gsector')[col].transform('mean'))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all other missing values imputed using KNN imputer\n",
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "num_cols = df.select_dtypes(include='number').columns\n",
    "imputer = KNNImputer(n_neighbors=3)\n",
    "df[num_cols] = imputer.fit_transform(df[num_cols])\n",
    "\n",
    "# still check for any missing values then simple fillna with column mean for numerical columns\n",
    "df.drop(['gind', 'gsector'], axis=1, inplace=True)\n",
    "num_cols = df.select_dtypes(include='number').columns\n",
    "for col in num_cols:\n",
    "    df[col] = df[col].fillna(df[col].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique tickers in fundamentals data: 468\n",
      "Number of unique tickers in price data: 516\n",
      "Number of common tickers: 453\n"
     ]
    }
   ],
   "source": [
    "price_tickers = price_df['ticker'].unique()\n",
    "fundamentals_tickers = df['ticker'].unique()\n",
    "common_tickers = set(price_tickers).intersection(set(fundamentals_tickers))\n",
    "print(f\"Number of unique tickers in fundamentals data: {len(fundamentals_tickers)}\")\n",
    "print(f\"Number of unique tickers in price data: {len(price_tickers)}\")\n",
    "print(f\"Number of common tickers: {len(common_tickers)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tickers in fundamentals data but missing in price data: 15\n"
     ]
    }
   ],
   "source": [
    "# Need to manually check which tickers are missing in either dataset\n",
    "missing_tickers = set(fundamentals_tickers) - common_tickers\n",
    "print(f\"Tickers in fundamentals data but missing in price data: {len(missing_tickers)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((9233, 17), (5438, 62))"
      ]
     },
     "execution_count": 373,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "price_df.shape, df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.set_index(['date', 'ticker'])\n",
    "price_df = price_df.set_index(['date', 'ticker'])\n",
    "df_merged = df.join(price_df, how='inner')\n",
    "df_merged.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4962, 77), 452)"
      ]
     },
     "execution_count": 375,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged.shape, len(df_merged['ticker'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_merged.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_merged.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], dtype=object)"
      ]
     },
     "execution_count": 378,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show tickers with a single missing values\n",
    "missing_tickers = df_merged[df_merged.isna().any(axis=1)]['ticker'].unique()\n",
    "missing_tickers # investigate these tickers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gvkey              0\n",
       "CAPEI              0\n",
       "bm                 0\n",
       "evm                0\n",
       "pe_op_basic        0\n",
       "pe_op_dil          0\n",
       "pe_exi             0\n",
       "pe_inc             0\n",
       "ps                 0\n",
       "pcf                0\n",
       "dpr                0\n",
       "npm                0\n",
       "opmbd              0\n",
       "opmad              0\n",
       "gpm                0\n",
       "ptpm               0\n",
       "cfm                0\n",
       "roa                0\n",
       "roe                0\n",
       "roce               0\n",
       "efftax             0\n",
       "aftret_eq          0\n",
       "aftret_invcapx     0\n",
       "aftret_equity      0\n",
       "pretret_earnat     0\n",
       "GProf              0\n",
       "equity_invcap      0\n",
       "debt_invcap        0\n",
       "totdebt_invcap     0\n",
       "capital_ratio      0\n",
       "int_debt           0\n",
       "int_totdebt        0\n",
       "cash_lt            0\n",
       "debt_at            0\n",
       "debt_ebitda        0\n",
       "short_debt         0\n",
       "lt_debt            0\n",
       "cash_debt          0\n",
       "fcf_ocf            0\n",
       "lt_ppent           0\n",
       "dltt_be            0\n",
       "debt_assets        0\n",
       "debt_capital       0\n",
       "de_ratio           0\n",
       "cash_ratio         0\n",
       "quick_ratio        0\n",
       "curr_ratio         0\n",
       "cash_conversion    0\n",
       "at_turn            0\n",
       "rect_turn          0\n",
       "pay_turn           0\n",
       "sale_invcap        0\n",
       "sale_equity        0\n",
       "rd_sale            0\n",
       "adv_sale           0\n",
       "staff_sale         0\n",
       "accrual            0\n",
       "ptb                0\n",
       "divyield           0\n",
       "cusip              0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 379,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 380,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# droping these tickers\n",
    "df_merged = df_merged[~df_merged['ticker'].isin(missing_tickers)]\n",
    "df_merged.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if above is not 0, see why"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save csv to be used in modeling\n",
    "df_merged.to_csv(f'Data/sp500_cleaned_{year}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4962, 77)"
      ]
     },
     "execution_count": 383,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "452\n",
      "2024\n"
     ]
    }
   ],
   "source": [
    "print(df_merged[\"ticker\"].nunique())\n",
    "print(year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_merged.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "volume     0\n",
       "price      0\n",
       "ret_1m     0\n",
       "ret_3m     0\n",
       "ret_6m     0\n",
       "SMA_3      0\n",
       "SMA_6      0\n",
       "vol_3m     0\n",
       "vol_6m     0\n",
       "EMA_3      0\n",
       "EMA_6      0\n",
       "RVOL_3     0\n",
       "RVOL_6     0\n",
       "vol_ROC    0\n",
       "vol_mom    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 386,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged[price_df.columns].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
