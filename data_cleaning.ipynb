{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('display.max_rows', None)\n",
    "from yahooquery import Ticker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "year = 2022\n",
    "df = pd.read_csv(f'Data/sp500_wrds_{year}_fundamental.csv')\n",
    "price_df = pd.read_csv(f'Data/sp500_wrds_{year}_price.csv') # include 12 months before data\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial_columns = ['permno', 'adate', 'qdate', 'public_date', 'bm', 'evm', 'pe_op_basic',\n",
    "#        'pe_op_dil', 'pe_exi', 'ps', 'pcf', 'dpr', 'npm', 'opmad', 'gpm',\n",
    "#        'ptpm', 'cfm', 'roa', 'roe', 'roce', 'efftax', 'aftret_eq',\n",
    "#        'aftret_invcapx', 'aftret_equity', 'pretret_noa', 'GProf',\n",
    "#        'equity_invcap', 'debt_invcap', 'totdebt_invcap', 'capital_ratio',\n",
    "#        'int_debt', 'int_totdebt', 'cash_lt', 'invt_act', 'rect_act', 'debt_at',\n",
    "#        'debt_ebitda', 'short_debt', 'curr_debt', 'lt_debt', 'profit_lct',\n",
    "#        'ocf_lct', 'cash_debt', 'fcf_ocf', 'lt_ppent', 'dltt_be', 'debt_assets',\n",
    "#        'debt_capital', 'de_ratio', 'intcov', 'intcov_ratio', 'inv_turn',\n",
    "#        'at_turn', 'rect_turn', 'pay_turn', 'sale_equity', 'sale_nwc',\n",
    "#        'rd_sale', 'adv_sale', 'staff_sale', 'accrual', 'ptb', 'PEG_trailing',\n",
    "#        'divyield', 'TICKER']\n",
    "# # some are dropped due to high missing values or redundancy after this block\n",
    "\n",
    "# df = df[initial_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_drop = ['permno','adate', 'qdate','PEG_trailing','inv_turn', 'sale_nwc','profit_lct','ocf_lct','curr_debt', 'pretret_noa', 'intcov', 'intcov_ratio', 'rect_act','invt_act']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=cols_to_drop)\n",
    "df = df.rename(columns={'TICKER': 'ticker', 'public_date': 'date'})\n",
    "df = df.dropna(subset=['ticker'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.isna().sum()\n",
    "df['date'] = pd.to_datetime(df['date'], format='%Y-%m-%d')\n",
    "# df.set_index('date', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remoce % sign from divyield and convert to float\n",
    "df[\"divyield\"] = df[\"divyield\"].str.rstrip('%')\n",
    "df[\"divyield\"] = df[\"divyield\"].fillna(0)\n",
    "df[\"divyield\"] = df[\"divyield\"].astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sort_values(['ticker', 'date'])\n",
    "df = df.groupby('ticker').apply(lambda x: x.ffill().bfill())\n",
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>bm</th>\n",
       "      <th>evm</th>\n",
       "      <th>pe_op_basic</th>\n",
       "      <th>pe_op_dil</th>\n",
       "      <th>pe_exi</th>\n",
       "      <th>ps</th>\n",
       "      <th>pcf</th>\n",
       "      <th>dpr</th>\n",
       "      <th>npm</th>\n",
       "      <th>...</th>\n",
       "      <th>rect_turn</th>\n",
       "      <th>pay_turn</th>\n",
       "      <th>sale_equity</th>\n",
       "      <th>rd_sale</th>\n",
       "      <th>adv_sale</th>\n",
       "      <th>staff_sale</th>\n",
       "      <th>accrual</th>\n",
       "      <th>ptb</th>\n",
       "      <th>divyield</th>\n",
       "      <th>ticker</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-01-31</td>\n",
       "      <td>0.115</td>\n",
       "      <td>29.262</td>\n",
       "      <td>33.251</td>\n",
       "      <td>33.652</td>\n",
       "      <td>35.360</td>\n",
       "      <td>6.658</td>\n",
       "      <td>28.333</td>\n",
       "      <td>0.195</td>\n",
       "      <td>0.191</td>\n",
       "      <td>...</td>\n",
       "      <td>5.719</td>\n",
       "      <td>6.955</td>\n",
       "      <td>1.173</td>\n",
       "      <td>0.070</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.027</td>\n",
       "      <td>7.661</td>\n",
       "      <td>0.557</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-02-28</td>\n",
       "      <td>0.115</td>\n",
       "      <td>29.262</td>\n",
       "      <td>31.112</td>\n",
       "      <td>31.488</td>\n",
       "      <td>33.086</td>\n",
       "      <td>6.197</td>\n",
       "      <td>26.367</td>\n",
       "      <td>0.195</td>\n",
       "      <td>0.191</td>\n",
       "      <td>...</td>\n",
       "      <td>5.719</td>\n",
       "      <td>6.955</td>\n",
       "      <td>1.173</td>\n",
       "      <td>0.070</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.027</td>\n",
       "      <td>7.130</td>\n",
       "      <td>0.595</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-03-31</td>\n",
       "      <td>0.123</td>\n",
       "      <td>26.424</td>\n",
       "      <td>31.810</td>\n",
       "      <td>32.119</td>\n",
       "      <td>33.586</td>\n",
       "      <td>6.162</td>\n",
       "      <td>26.441</td>\n",
       "      <td>0.199</td>\n",
       "      <td>0.187</td>\n",
       "      <td>...</td>\n",
       "      <td>5.636</td>\n",
       "      <td>6.461</td>\n",
       "      <td>1.270</td>\n",
       "      <td>0.071</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.029</td>\n",
       "      <td>7.705</td>\n",
       "      <td>0.000</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-04-30</td>\n",
       "      <td>0.123</td>\n",
       "      <td>26.424</td>\n",
       "      <td>28.671</td>\n",
       "      <td>28.949</td>\n",
       "      <td>30.272</td>\n",
       "      <td>5.554</td>\n",
       "      <td>23.831</td>\n",
       "      <td>0.199</td>\n",
       "      <td>0.187</td>\n",
       "      <td>...</td>\n",
       "      <td>5.636</td>\n",
       "      <td>6.461</td>\n",
       "      <td>1.270</td>\n",
       "      <td>0.071</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.029</td>\n",
       "      <td>6.945</td>\n",
       "      <td>0.704</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-05-31</td>\n",
       "      <td>0.123</td>\n",
       "      <td>26.424</td>\n",
       "      <td>30.663</td>\n",
       "      <td>30.961</td>\n",
       "      <td>32.376</td>\n",
       "      <td>5.940</td>\n",
       "      <td>25.488</td>\n",
       "      <td>0.199</td>\n",
       "      <td>0.187</td>\n",
       "      <td>...</td>\n",
       "      <td>5.636</td>\n",
       "      <td>6.461</td>\n",
       "      <td>1.270</td>\n",
       "      <td>0.071</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.029</td>\n",
       "      <td>7.428</td>\n",
       "      <td>0.659</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        date     bm     evm  pe_op_basic  pe_op_dil  pe_exi     ps     pcf  \\\n",
       "0 2022-01-31  0.115  29.262       33.251     33.652  35.360  6.658  28.333   \n",
       "1 2022-02-28  0.115  29.262       31.112     31.488  33.086  6.197  26.367   \n",
       "2 2022-03-31  0.123  26.424       31.810     32.119  33.586  6.162  26.441   \n",
       "3 2022-04-30  0.123  26.424       28.671     28.949  30.272  5.554  23.831   \n",
       "4 2022-05-31  0.123  26.424       30.663     30.961  32.376  5.940  25.488   \n",
       "\n",
       "     dpr    npm  ...  rect_turn  pay_turn  sale_equity  rd_sale  adv_sale  \\\n",
       "0  0.195  0.191  ...      5.719     6.955        1.173    0.070      0.01   \n",
       "1  0.195  0.191  ...      5.719     6.955        1.173    0.070      0.01   \n",
       "2  0.199  0.187  ...      5.636     6.461        1.270    0.071      0.01   \n",
       "3  0.199  0.187  ...      5.636     6.461        1.270    0.071      0.01   \n",
       "4  0.199  0.187  ...      5.636     6.461        1.270    0.071      0.01   \n",
       "\n",
       "   staff_sale  accrual    ptb  divyield  ticker  \n",
       "0         0.0   -0.027  7.661     0.557       A  \n",
       "1         0.0   -0.027  7.130     0.595       A  \n",
       "2         0.0   -0.029  7.705     0.000       A  \n",
       "3         0.0   -0.029  6.945     0.704       A  \n",
       "4         0.0   -0.029  7.428     0.659       A  \n",
       "\n",
       "[5 rows x 51 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2022 specific"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# renam fb ticker to meta (2022 change)\n",
    "df['ticker'] = df['ticker'].replace({'FB': 'META'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "469\n"
     ]
    }
   ],
   "source": [
    "print(len(df[\"ticker\"].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['tic', 'datadate', 'gvkey', 'ggroup', 'gind', 'gsector', 'cshtrm',\n",
       "       'prccm'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "price_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dictionary to map ticker to gind\n",
    "gind_mapping = price_df.set_index('tic')['gind'].to_dict()\n",
    "gsec_mapping = price_df.set_index('tic')['gsector'].to_dict()\n",
    "df['gind'] = df['ticker'].map(gind_mapping)\n",
    "df['gsector'] = df['ticker'].map(gsec_mapping)\n",
    "\n",
    "\n",
    "price_df = price_df[['tic', 'datadate', 'cshtrm', 'prccm']]\n",
    "price_df = price_df.rename(columns={'tic': 'ticker', 'datadate': 'date', 'cshtrm': 'volume', 'prccm': 'price'}) # rename columns\n",
    "price_df['date'] = pd.to_datetime(price_df['date'], format='%Y-%m-%d')\n",
    "# price_df.set_index('date', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "group = price_df.groupby('ticker')\n",
    "\n",
    "# 1. Simple Moving Averages\n",
    "price_df['SMA_3']  = group['price'].transform(lambda x: x.rolling(3).mean())\n",
    "price_df['SMA_6']  = group['price'].transform(lambda x: x.rolling(6).mean())\n",
    "# price_df['SMA_12'] = group['price'].transform(lambda x: x.rolling(12).mean())\n",
    "\n",
    "# 2. Price Returns / Momentum\n",
    "price_df['ret_1m']  = group['price'].transform(lambda x: x.pct_change())\n",
    "price_df['ret_3m']  = group['price'].transform(lambda x: x.pct_change(3))\n",
    "price_df['ret_6m']  = group['price'].transform(lambda x: x.pct_change(6))\n",
    "# price_df['ret_12m'] = group['price'].transform(lambda x: x.pct_change(12))\n",
    "\n",
    "# 3. Volatility (Rolling Std of returns)\n",
    "price_df['vol_3m']  = group['ret_1m'].transform(lambda x: x.rolling(3).std())\n",
    "price_df['vol_6m']  = group['ret_1m'].transform(lambda x: x.rolling(6).std())\n",
    "# price_df['vol_12m'] = group['ret_1m'].transform(lambda x: x.rolling(12).std())\n",
    "\n",
    "# 4. Exponential Moving Average\n",
    "price_df['EMA_6']  = group['price'].transform(lambda x: x.ewm(span=6, adjust=False).mean())\n",
    "price_df['EMA_12'] = group['price'].transform(lambda x: x.ewm(span=12, adjust=False).mean())\n",
    "\n",
    "# 5. RSI (approx price-only RSI)\n",
    "def rsi(series, period=6):\n",
    "    delta = series.diff()\n",
    "    gain = delta.clip(lower=0).rolling(period).mean()\n",
    "    loss = -delta.clip(upper=0).rolling(period).mean()\n",
    "    rs = gain / loss\n",
    "    return 100 - (100/(1 + rs))\n",
    "\n",
    "price_df['RSI'] = group['price'].transform(rsi)\n",
    "\n",
    "# 6. MACD\n",
    "exp1 = group['price'].transform(lambda x: x.ewm(span=12, adjust=False).mean())\n",
    "exp2 = group['price'].transform(lambda x: x.ewm(span=26, adjust=False).mean())\n",
    "price_df['MACD_ratio'] = (exp1 - exp2) / price_df['price']\n",
    "\n",
    "\n",
    "# 7. Volume moving average\n",
    "price_df['vol_SMA_3'] = group['volume'].transform(lambda x: x.rolling(3).mean())\n",
    "price_df['vol_SMA_6'] = group['volume'].transform(lambda x: x.rolling(6).mean())\n",
    "\n",
    "# 8. Volume Rate of Change\n",
    "price_df['vol_ROC'] = group['volume'].transform(lambda x: x.pct_change())\n",
    "\n",
    "# 9. OBV (On-Balance Volume)\n",
    "def obv(df):\n",
    "    sign = df['price'].diff().apply(lambda x: 1 if x>0 else -1 if x<0 else 0)\n",
    "    return (sign * df['volume']).cumsum()\n",
    "\n",
    "price_df['OBV'] = group.apply(obv).reset_index(level=0, drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ticker', 'date', 'volume', 'price', 'SMA_3', 'SMA_6', 'ret_1m',\n",
       "       'ret_3m', 'ret_6m', 'vol_3m', 'vol_6m', 'EMA_6', 'EMA_12', 'RSI',\n",
       "       'MACD_ratio', 'vol_SMA_3', 'vol_SMA_6', 'vol_ROC', 'OBV'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "price_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "nans_col = df.isna().sum()\n",
    "missing_columns = nans_col[nans_col > 0]\n",
    "\n",
    "for col in missing_columns.index:\n",
    "    if col not in ['gind', 'gsector']:\n",
    "        # 1. Fill using industry mean\n",
    "        df[col] = df[col].fillna(df.groupby('gind')[col].transform('mean'))\n",
    "        # 2. Fill remaining using sector mean\n",
    "        df[col] = df[col].fillna(df.groupby('gsector')[col].transform('mean'))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['date', 'bm', 'evm', 'pe_op_basic', 'pe_op_dil', 'pe_exi', 'ps', 'pcf',\n",
       "       'dpr', 'npm', 'opmad', 'gpm', 'ptpm', 'cfm', 'roa', 'roe', 'roce',\n",
       "       'efftax', 'aftret_eq', 'aftret_invcapx', 'aftret_equity', 'GProf',\n",
       "       'equity_invcap', 'debt_invcap', 'totdebt_invcap', 'capital_ratio',\n",
       "       'int_debt', 'int_totdebt', 'cash_lt', 'debt_at', 'debt_ebitda',\n",
       "       'short_debt', 'lt_debt', 'cash_debt', 'fcf_ocf', 'lt_ppent', 'dltt_be',\n",
       "       'debt_assets', 'debt_capital', 'de_ratio', 'at_turn', 'rect_turn',\n",
       "       'pay_turn', 'sale_equity', 'rd_sale', 'adv_sale', 'staff_sale',\n",
       "       'accrual', 'ptb', 'divyield', 'ticker', 'gind', 'gsector'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all other missing values imputed using KNN imputer\n",
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "num_cols = df.select_dtypes(include='number').columns\n",
    "imputer = KNNImputer(n_neighbors=3)\n",
    "df[num_cols] = imputer.fit_transform(df[num_cols])\n",
    "\n",
    "# still check for any missing values then simple fillna with column mean for numerical columns\n",
    "df.drop(['gind', 'gsector'], axis=1, inplace=True)\n",
    "num_cols = df.select_dtypes(include='number').columns\n",
    "for col in num_cols:\n",
    "    df[col] = df[col].fillna(df[col].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique tickers in fundamentals data: 469\n",
      "Number of unique tickers in price data: 510\n",
      "Number of common tickers: 443\n"
     ]
    }
   ],
   "source": [
    "price_tickers = price_df['ticker'].unique()\n",
    "fundamentals_tickers = df['ticker'].unique()\n",
    "common_tickers = set(price_tickers).intersection(set(fundamentals_tickers))\n",
    "print(f\"Number of unique tickers in fundamentals data: {len(fundamentals_tickers)}\")\n",
    "print(f\"Number of unique tickers in price data: {len(price_tickers)}\")\n",
    "print(f\"Number of common tickers: {len(common_tickers)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tickers in fundamentals data but missing in price data: {'PKI', 'BH', 'CMT', 'MLSS', 'WABC', 'FRC', 'FBHS', 'TCX', 'CDAY', 'AMR', 'COG', 'COOP', 'LEE', 'DISCA', 'PAR', 'APLD', 'FLT', 'ANTM', 'WW', 'ITI', 'NLOK', 'PARA', 'BLL', 'ATI', 'SIVB', 'ABC'}\n"
     ]
    }
   ],
   "source": [
    "# Need to manually check which tickers are missing in either dataset\n",
    "missing_tickers = set(fundamentals_tickers) - common_tickers\n",
    "print(f\"Tickers in fundamentals data but missing in price data: {missing_tickers}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.set_index(['date', 'ticker'])\n",
    "price_df = price_df.set_index(['date', 'ticker'])\n",
    "df_merged = df.join(price_df, how='inner')\n",
    "df_merged.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5171, 68), 443)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged.shape, len(df_merged['ticker'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_merged.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['CEG'], dtype=object)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show tickers with a single missing values\n",
    "missing_tickers = df_merged[df_merged.isna().any(axis=1)]['ticker'].unique()\n",
    "missing_tickers # investigate these tickers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# droping these tickers\n",
    "df_merged = df_merged[~df_merged['ticker'].isin(missing_tickers)]\n",
    "df_merged.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if above is not 0, see why"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(66, 66)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged[cols].corr().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save csv to be used in modeling\n",
    "df_merged.to_csv(f'Data/sp500_cleaned_{year}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5163, 68)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "# get spy montlhy last day from yfinance\n",
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "\n",
    "spy = yf.download(\"SPY\", start=\"2019-01-01\", interval=\"1d\")\n",
    "spy_monthly = spy.resample('M').last()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_spy = spy_monthly[\"Close\"].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_spy.to_csv('Data/SPY.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Ticker</th>\n",
       "      <th>Date</th>\n",
       "      <th>SPY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-01-31</td>\n",
       "      <td>243.474564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-02-28</td>\n",
       "      <td>251.366882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-03-31</td>\n",
       "      <td>255.916763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-04-30</td>\n",
       "      <td>266.371613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-05-31</td>\n",
       "      <td>249.384796</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Ticker       Date         SPY\n",
       "0      2019-01-31  243.474564\n",
       "1      2019-02-28  251.366882\n",
       "2      2019-03-31  255.916763\n",
       "3      2019-04-30  266.371613\n",
       "4      2019-05-31  249.384796"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_spy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
